{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1: Data Ingestion and  Data Preprocessing\n",
    "Set up a data ingestion system to fetch messages from multiple  Ethiopian-based Telegram e-commerce channels. Prepare the raw data (text, images) for entity extraction.\n",
    "List of channels \n",
    "You have to select atleast 5 channels to fetch data and you can share each other since fine tuning needs more data\n",
    "Steps:\n",
    "Identify and connect to relevant Telegram channels using a custom scraper.\n",
    "Implement a message ingestion system to collect text, images, and documents as they are posted in real time.\n",
    "Preprocess text data by tokenizing, normalizing, and handling Amharic-specific linguistic features.\n",
    "Clean and structure the data into a unified format, separating metadata (e.g., sender, timestamp) from message content.\n",
    "Store preprocessed data in a structured format for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from clean import delete_null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=28083480\n",
    "hash='075e74a23e6e74708690f1f11bf0b266'\n",
    "phone_number='0919180119'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon import TelegramClient\n",
    "import csv\n",
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy.exc import OperationalError\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env')\n",
    "api_id = id\n",
    "api_hash = hash\n",
    "\n",
    "# Function to scrape data from a single channel\n",
    "async def scrape_channel(client, channel_username, writer, media_dir):\n",
    "    entity = await client.get_entity(channel_username)\n",
    "    channel_title = entity.title\n",
    "    async for message in client.iter_messages(entity, limit=100):\n",
    "        media_path = None\n",
    "        if message.media and hasattr(message.media, 'photo'):\n",
    "            filename = f\"{channel_username}_{message.id}.jpg\"\n",
    "            media_path = os.path.join(media_dir, filename)\n",
    "            await client.download_media(message.media, media_path)\n",
    "        writer.writerow([channel_title, channel_username, message.id, message.message, message.date, media_path])\n",
    "\n",
    "async def main():\n",
    "    async with TelegramClient('scraping_session', api_id, api_hash, timeout=10) as client:\n",
    "        media_dir = 'photos'\n",
    "        os.makedirs(media_dir, exist_ok=True)\n",
    "\n",
    "        with open('telegram_data.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Channel Title', 'Channel Username', 'ID', 'Message', 'Date', 'Media Path'])\n",
    "            channels = ['@Shageronlinestore', '@ZemenExpress','@AwasMart','@leyueqa','@sinayelj']\n",
    "            for channel in channels:\n",
    "                success = False\n",
    "                while not success:\n",
    "                    try:\n",
    "                        await scrape_channel(client, channel, writer, media_dir)\n",
    "                        success = True\n",
    "                        print(f\"Scraped data from {channel}\")\n",
    "                    except OperationalError as e:\n",
    "                        print(f\"Database is locked. Retrying... {e}\")\n",
    "                        await asyncio.sleep(1)  # Wait before retrying\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r\"C:\\Users\\ASUS VIVO\\Downloads\\new.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sheger online-store', 'Zemen Express', 'Sinayelij', 'Leyueqa',\n",
       "       'AwasMart'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Channel Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after dropping NaN values in 'Message' column: (3257, 6)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['Message'])\n",
    "\n",
    "# Print the shape of the dataset after dropping NaN values in the \"Message\" column\n",
    "print(f\"Dataset shape after dropping NaN values in 'Message' column: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Message'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Channel Title    Channel Username    ID  \\\n",
      "2  Sheger online-store  @Shageronlinestore  3791   \n",
      "4  Sheger online-store  @Shageronlinestore  1100   \n",
      "5  Sheger online-store  @Shageronlinestore  1037   \n",
      "7  Sheger online-store  @Shageronlinestore   672   \n",
      "8  Sheger online-store  @Shageronlinestore  4220   \n",
      "\n",
      "                                             Message  \\\n",
      "2   Yoga mat\\n\\nSize  61cm*173cm*4mm\\n\\nዋጋ፦     7...   \n",
      "4   Marado Electric Kettle \\n\\n 1.7L Capacity \\n ...   \n",
      "5   3.6L Glass dispenser jar with Bamboo stand\\n\\...   \n",
      "7  detangling Curling brush\\n    \\nዋጋ- 300ብር\\n\\n ...   \n",
      "8                      How to set up detagling brush   \n",
      "\n",
      "                        Date                          Media Path  \n",
      "2  2023-03-18 07:17:30+00:00  photos/@Shageronlinestore_1319.jpg  \n",
      "4  2024-05-15 17:00:19+00:00  photos/@Shageronlinestore_4155.jpg  \n",
      "5  2024-05-21 12:26:09+00:00  photos/@Shageronlinestore_4219.jpg  \n",
      "7  2024-06-26 15:20:48+00:00                                 NaN  \n",
      "8  2022-12-02 14:23:45+00:00                                 NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS VIVO\\AppData\\Local\\Temp\\ipykernel_16444\\3338464784.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Message'] = df['Message'].apply(remove_emojis)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "df['Message'] = df['Message'].apply(remove_emojis)\n",
    "\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Media Path' ,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelled the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def label_message_utf8_with_birr(message):\n",
    "    # Split the message at the first occurrence of '\\n'\n",
    "    if '\\n' in message:\n",
    "        first_line, remaining_message = message.split('\\n', 1)\n",
    "    else:\n",
    "        first_line, remaining_message = message, \"\"\n",
    "    \n",
    "    labeled_tokens = []\n",
    "    \n",
    "    # Tokenize the first line\n",
    "    first_line_tokens = re.findall(r'\\S+', first_line)\n",
    "    \n",
    "    # Label the first token as B-PRODUCT and the rest as I-PRODUCT\n",
    "    if first_line_tokens:\n",
    "        labeled_tokens.append(f\"{first_line_tokens[0]} B-PRODUCT\")  # First token as B-PRODUCT\n",
    "        for token in first_line_tokens[1:]:\n",
    "            labeled_tokens.append(f\"{token} I-PRODUCT\")  # Remaining tokens as I-PRODUCT\n",
    "    \n",
    "    # Process the remaining message normally\n",
    "    if remaining_message:\n",
    "        lines = remaining_message.split('\\n')\n",
    "        for line in lines:\n",
    "            tokens = re.findall(r'\\S+', line)  # Tokenize each line while considering non-ASCII characters\n",
    "            \n",
    "            for token in tokens:\n",
    "                # Check if token is a price (e.g., 500 ETB, $100, or ብር)\n",
    "                if re.match(r'^\\d{10,}$', token):\n",
    "                    labeled_tokens.append(f\"{token} O\")  # Label as O for \"other\" or outside of any entity\n",
    "                elif re.match(r'^\\d+(\\.\\d{1,2})?$', token) or 'ETB' in token or 'ዋጋ' in token or '$' in token or 'ብር' in token:\n",
    "                    labeled_tokens.append(f\"{token} I-PRICE\")\n",
    "                # Check if token could be a location (e.g., cities or general location names)\n",
    "                elif any(loc in token for loc in ['Addis Ababa', 'ለቡ', 'ለቡ መዳህኒዓለም', 'መገናኛ', 'ቦሌ', 'ሜክሲኮ']):\n",
    "                    labeled_tokens.append(f\"{token} I-LOC\")\n",
    "                # Assume other tokens are part of a product name or general text\n",
    "                else:\n",
    "                    labeled_tokens.append(f\"{token} O\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the updated function to the non-null messages\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_utf8_with_birr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Labeled_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>AwasMart</td>\n",
       "      <td>@AwasMart</td>\n",
       "      <td>5081</td>\n",
       "      <td>Aromatherapy humidifier, difuser\\n\\n Brings cl...</td>\n",
       "      <td>2022-02-01 19:14:29+00:00</td>\n",
       "      <td>Aromatherapy B-PRODUCT\\nhumidifier, I-PRODUCT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>AwasMart</td>\n",
       "      <td>@AwasMart</td>\n",
       "      <td>5094</td>\n",
       "      <td>Robotic Cushion Massage Seat For Car / Home</td>\n",
       "      <td>2022-01-23 19:28:49+00:00</td>\n",
       "      <td>Robotic B-PRODUCT\\nCushion I-PRODUCT\\nMassage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>AwasMart</td>\n",
       "      <td>@AwasMart</td>\n",
       "      <td>5077</td>\n",
       "      <td>ለጤናችን-Health &amp; Personal Care\\n\\nFingerTip Puls...</td>\n",
       "      <td>2021-04-12 08:36:40+00:00</td>\n",
       "      <td>ለጤናችን-Health B-PRODUCT\\n&amp; I-PRODUCT\\nPersonal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>AwasMart</td>\n",
       "      <td>@AwasMart</td>\n",
       "      <td>5100</td>\n",
       "      <td>Reusable convenience LVy Grip Tape\\n\\nSize: 3...</td>\n",
       "      <td>2022-01-21 10:15:06+00:00</td>\n",
       "      <td>Reusable B-PRODUCT\\nconvenience I-PRODUCT\\nLVy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>AwasMart</td>\n",
       "      <td>@AwasMart</td>\n",
       "      <td>5107</td>\n",
       "      <td>Saachi 3in1 Blender / Grinder\\nለጁስ\\nለቡና እንዲሁም ...</td>\n",
       "      <td>2022-01-17 04:08:15+00:00</td>\n",
       "      <td>Saachi B-PRODUCT\\n3in1 I-PRODUCT\\nBlender I-PR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Channel Title Channel Username    ID  \\\n",
       "271      AwasMart        @AwasMart  5081   \n",
       "359      AwasMart        @AwasMart  5094   \n",
       "698      AwasMart        @AwasMart  5077   \n",
       "927      AwasMart        @AwasMart  5100   \n",
       "943      AwasMart        @AwasMart  5107   \n",
       "\n",
       "                                               Message  \\\n",
       "271  Aromatherapy humidifier, difuser\\n\\n Brings cl...   \n",
       "359        Robotic Cushion Massage Seat For Car / Home   \n",
       "698  ለጤናችን-Health & Personal Care\\n\\nFingerTip Puls...   \n",
       "927   Reusable convenience LVy Grip Tape\\n\\nSize: 3...   \n",
       "943  Saachi 3in1 Blender / Grinder\\nለጁስ\\nለቡና እንዲሁም ...   \n",
       "\n",
       "                          Date  \\\n",
       "271  2022-02-01 19:14:29+00:00   \n",
       "359  2022-01-23 19:28:49+00:00   \n",
       "698  2021-04-12 08:36:40+00:00   \n",
       "927  2022-01-21 10:15:06+00:00   \n",
       "943  2022-01-17 04:08:15+00:00   \n",
       "\n",
       "                                       Labeled_Message  \n",
       "271  Aromatherapy B-PRODUCT\\nhumidifier, I-PRODUCT\\...  \n",
       "359  Robotic B-PRODUCT\\nCushion I-PRODUCT\\nMassage ...  \n",
       "698  ለጤናችን-Health B-PRODUCT\\n& I-PRODUCT\\nPersonal ...  \n",
       "927  Reusable B-PRODUCT\\nconvenience I-PRODUCT\\nLVy...  \n",
       "943  Saachi B-PRODUCT\\n3in1 I-PRODUCT\\nBlender I-PR...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Channel Title']=='AwasMart'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Labeled_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Leyueqa</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5059</td>\n",
       "      <td>ከ\"ጃር\" ላይ የመጠጥ ዉሃ የሚስብ ተንቀሳቃሽ ማሽን\\n......water ...</td>\n",
       "      <td>2021-10-28 15:48:02+00:00</td>\n",
       "      <td>ከ\"ጃር\" B-PRODUCT\\nላይ I-PRODUCT\\nየመጠጥ I-PRODUCT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>Leyueqa</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5051</td>\n",
       "      <td>Mini  Ultrasonic turbine washer</td>\n",
       "      <td>2021-10-31 04:22:41+00:00</td>\n",
       "      <td>Mini B-PRODUCT\\nUltrasonic I-PRODUCT\\nturbine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>Leyueqa</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5048</td>\n",
       "      <td>Retractable Clothesline Rope</td>\n",
       "      <td>2021-10-31 04:25:38+00:00</td>\n",
       "      <td>Retractable B-PRODUCT\\nClothesline I-PRODUCT\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>Leyueqa</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5060</td>\n",
       "      <td>Anti-theft Lightweight Backpack 15.6\"\\n      ...</td>\n",
       "      <td>2021-10-25 07:59:46+00:00</td>\n",
       "      <td>Anti-theft B-PRODUCT\\nLightweight I-PRODUCT\\nB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>Leyueqa</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5055</td>\n",
       "      <td>Sweat Shaper\\n      Slimming body shaper \\n\\nለ...</td>\n",
       "      <td>2021-10-30 14:19:16+00:00</td>\n",
       "      <td>Sweat B-PRODUCT\\nShaper I-PRODUCT\\nSlimming O\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Title Channel Username    ID  \\\n",
       "181        Leyueqa         @Leyueqa  5059   \n",
       "1369       Leyueqa         @Leyueqa  5051   \n",
       "2501       Leyueqa         @Leyueqa  5048   \n",
       "2882       Leyueqa         @Leyueqa  5060   \n",
       "2891       Leyueqa         @Leyueqa  5055   \n",
       "\n",
       "                                                Message  \\\n",
       "181   ከ\"ጃር\" ላይ የመጠጥ ዉሃ የሚስብ ተንቀሳቃሽ ማሽን\\n......water ...   \n",
       "1369                    Mini  Ultrasonic turbine washer   \n",
       "2501                       Retractable Clothesline Rope   \n",
       "2882   Anti-theft Lightweight Backpack 15.6\"\\n      ...   \n",
       "2891  Sweat Shaper\\n      Slimming body shaper \\n\\nለ...   \n",
       "\n",
       "                           Date  \\\n",
       "181   2021-10-28 15:48:02+00:00   \n",
       "1369  2021-10-31 04:22:41+00:00   \n",
       "2501  2021-10-31 04:25:38+00:00   \n",
       "2882  2021-10-25 07:59:46+00:00   \n",
       "2891  2021-10-30 14:19:16+00:00   \n",
       "\n",
       "                                        Labeled_Message  \n",
       "181   ከ\"ጃር\" B-PRODUCT\\nላይ I-PRODUCT\\nየመጠጥ I-PRODUCT\\...  \n",
       "1369  Mini B-PRODUCT\\nUltrasonic I-PRODUCT\\nturbine ...  \n",
       "2501  Retractable B-PRODUCT\\nClothesline I-PRODUCT\\n...  \n",
       "2882  Anti-theft B-PRODUCT\\nLightweight I-PRODUCT\\nB...  \n",
       "2891  Sweat B-PRODUCT\\nShaper I-PRODUCT\\nSlimming O\\...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Channel Title']=='Leyueqa'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the updated labeled dataset to a file in CoNLL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_data_birr_path = r\"C:\\Users\\ASUS VIVO\\Downloads\\labele_data.txt-\"\n",
    "with open(labeled_data_birr_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
